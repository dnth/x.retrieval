{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coco-val-2017']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xretrieval\n",
    "\n",
    "xretrieval.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 12:12:57.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxretrieval.datasets.coco\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mCOCO validation dataset found in data/coco/val2017, skipping download\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = xretrieval.load_dataset(\"coco-val-2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>data/coco/val2017/000000000139.jpg</td>\n",
       "      <td>A woman stands in the dining area at the table...</td>\n",
       "      <td>book,chair,clock,dining table,microwave,person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>000000000285.jpg</td>\n",
       "      <td>data/coco/val2017/000000000285.jpg</td>\n",
       "      <td>A big burly grizzly bear is show with grass in...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>000000000632.jpg</td>\n",
       "      <td>data/coco/val2017/000000000632.jpg</td>\n",
       "      <td>Bedroom scene with a bookcase, blue comforter ...</td>\n",
       "      <td>bed,book,chair,potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724</td>\n",
       "      <td>000000000724.jpg</td>\n",
       "      <td>data/coco/val2017/000000000724.jpg</td>\n",
       "      <td>A stop sign is mounted upside-down on it's pos...</td>\n",
       "      <td>car,stop sign,truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>776</td>\n",
       "      <td>000000000776.jpg</td>\n",
       "      <td>data/coco/val2017/000000000776.jpg</td>\n",
       "      <td>Three teddy bears, each a different color, snu...</td>\n",
       "      <td>bed,teddy bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>581317</td>\n",
       "      <td>000000581317.jpg</td>\n",
       "      <td>data/coco/val2017/000000581317.jpg</td>\n",
       "      <td>A woman holding a small item in a field. Woman...</td>\n",
       "      <td>cell phone,person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>581357</td>\n",
       "      <td>000000581357.jpg</td>\n",
       "      <td>data/coco/val2017/000000581357.jpg</td>\n",
       "      <td>Skate boarder hang time with young man appeari...</td>\n",
       "      <td>bench,person,skateboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>581482</td>\n",
       "      <td>000000581482.jpg</td>\n",
       "      <td>data/coco/val2017/000000581482.jpg</td>\n",
       "      <td>A fancy metal cloth is seen against huge barre...</td>\n",
       "      <td>clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>581615</td>\n",
       "      <td>000000581615.jpg</td>\n",
       "      <td>data/coco/val2017/000000581615.jpg</td>\n",
       "      <td>A picture of a white toilet in the rest room. ...</td>\n",
       "      <td>toilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>581781</td>\n",
       "      <td>000000581781.jpg</td>\n",
       "      <td>data/coco/val2017/000000581781.jpg</td>\n",
       "      <td>A store display filled with ripe, unripe banan...</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id         file_name                          image_path  \\\n",
       "0          139  000000000139.jpg  data/coco/val2017/000000000139.jpg   \n",
       "1          285  000000000285.jpg  data/coco/val2017/000000000285.jpg   \n",
       "2          632  000000000632.jpg  data/coco/val2017/000000000632.jpg   \n",
       "3          724  000000000724.jpg  data/coco/val2017/000000000724.jpg   \n",
       "4          776  000000000776.jpg  data/coco/val2017/000000000776.jpg   \n",
       "...        ...               ...                                 ...   \n",
       "4995    581317  000000581317.jpg  data/coco/val2017/000000581317.jpg   \n",
       "4996    581357  000000581357.jpg  data/coco/val2017/000000581357.jpg   \n",
       "4997    581482  000000581482.jpg  data/coco/val2017/000000581482.jpg   \n",
       "4998    581615  000000581615.jpg  data/coco/val2017/000000581615.jpg   \n",
       "4999    581781  000000581781.jpg  data/coco/val2017/000000581781.jpg   \n",
       "\n",
       "                                                caption  \\\n",
       "0     A woman stands in the dining area at the table...   \n",
       "1     A big burly grizzly bear is show with grass in...   \n",
       "2     Bedroom scene with a bookcase, blue comforter ...   \n",
       "3     A stop sign is mounted upside-down on it's pos...   \n",
       "4     Three teddy bears, each a different color, snu...   \n",
       "...                                                 ...   \n",
       "4995  A woman holding a small item in a field. Woman...   \n",
       "4996  Skate boarder hang time with young man appeari...   \n",
       "4997  A fancy metal cloth is seen against huge barre...   \n",
       "4998  A picture of a white toilet in the rest room. ...   \n",
       "4999  A store display filled with ripe, unripe banan...   \n",
       "\n",
       "                                                   name  \n",
       "0     book,chair,clock,dining table,microwave,person...  \n",
       "1                                                  bear  \n",
       "2                           bed,book,chair,potted plant  \n",
       "3                                   car,stop sign,truck  \n",
       "4                                        bed,teddy bear  \n",
       "...                                                 ...  \n",
       "4995                                  cell phone,person  \n",
       "4996                            bench,person,skateboard  \n",
       "4997                                              clock  \n",
       "4998                                             toilet  \n",
       "4999                                             banana  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Available Models                              </span>\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Implementation </span>┃<span style=\"font-weight: bold\"> Model ID                          </span>┃<span style=\"font-weight: bold\"> Input --&gt; Output    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b-coco    </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-flan-t5-xxl      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-2.7b         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> sashakunitsyn/vlrm-blip2-opt-2.7b </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "└────────────────┴───────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                              Available Models                              \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mImplementation\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModel ID                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInput --> Output   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b-coco   \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-flan-t5-xxl     \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-2.7b        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35msashakunitsyn/vlrm-blip2-opt-2.7b\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "└────────────────┴───────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xinfer\n",
    "\n",
    "xinfer.list_models(\"blip2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 12:12:59.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mModel: Salesforce/blip2-opt-2.7b\u001b[0m\n",
      "\u001b[32m2024-11-20 12:12:59.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mDevice: cuda\u001b[0m\n",
      "\u001b[32m2024-11-20 12:12:59.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mDtype: float16\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00f0b00efa64c039bb7422c09d63bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xinfer.create_model(\"Salesforce/blip2-opt-2.7b\", device=\"cuda\", dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_id', 'file_name', 'image_path', 'caption', 'name'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_captions_batch(examples):\n",
    "    image_paths = [filename for filename in examples['image_path']]\n",
    "    prompts = [\"\"] * len(image_paths) \n",
    "    \n",
    "    results = model.infer_batch(image_paths, prompts, max_new_tokens=20)\n",
    "    captions = [res.text for res in results]\n",
    "\n",
    "    examples['blip2_caption'] = captions\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a327d600a82241fb9a5cacda0fffd95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating captions:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_id', 'file_name', 'image_path', 'caption', 'name', 'blip2_caption'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blip2_captioned_dataset = dataset.map(generate_captions_batch, batched=True, batch_size=200, desc=\"Generating captions\")\n",
    "blip2_captioned_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>name</th>\n",
       "      <th>blip2_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>data/coco/val2017/000000000139.jpg</td>\n",
       "      <td>A woman stands in the dining area at the table...</td>\n",
       "      <td>book,chair,clock,dining table,microwave,person...</td>\n",
       "      <td>a living room with a fireplace and a table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>000000000285.jpg</td>\n",
       "      <td>data/coco/val2017/000000000285.jpg</td>\n",
       "      <td>A big burly grizzly bear is show with grass in...</td>\n",
       "      <td>bear</td>\n",
       "      <td>a brown bear sitting on the grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>000000000632.jpg</td>\n",
       "      <td>data/coco/val2017/000000000632.jpg</td>\n",
       "      <td>Bedroom scene with a bookcase, blue comforter ...</td>\n",
       "      <td>bed,book,chair,potted plant</td>\n",
       "      <td>a bedroom with a bed, a dresser, a bookcase an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724</td>\n",
       "      <td>000000000724.jpg</td>\n",
       "      <td>data/coco/val2017/000000000724.jpg</td>\n",
       "      <td>A stop sign is mounted upside-down on it's pos...</td>\n",
       "      <td>car,stop sign,truck</td>\n",
       "      <td>a stop sign on a street corner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>776</td>\n",
       "      <td>000000000776.jpg</td>\n",
       "      <td>data/coco/val2017/000000000776.jpg</td>\n",
       "      <td>Three teddy bears, each a different color, snu...</td>\n",
       "      <td>bed,teddy bear</td>\n",
       "      <td>a group of three teddy bears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>581317</td>\n",
       "      <td>000000581317.jpg</td>\n",
       "      <td>data/coco/val2017/000000581317.jpg</td>\n",
       "      <td>A woman holding a small item in a field. Woman...</td>\n",
       "      <td>cell phone,person</td>\n",
       "      <td>a woman standing on a hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>581357</td>\n",
       "      <td>000000581357.jpg</td>\n",
       "      <td>data/coco/val2017/000000581357.jpg</td>\n",
       "      <td>Skate boarder hang time with young man appeari...</td>\n",
       "      <td>bench,person,skateboard</td>\n",
       "      <td>a man on a skateboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>581482</td>\n",
       "      <td>000000581482.jpg</td>\n",
       "      <td>data/coco/val2017/000000581482.jpg</td>\n",
       "      <td>A fancy metal cloth is seen against huge barre...</td>\n",
       "      <td>clock</td>\n",
       "      <td>a large clock in a large building with a large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>581615</td>\n",
       "      <td>000000581615.jpg</td>\n",
       "      <td>data/coco/val2017/000000581615.jpg</td>\n",
       "      <td>A picture of a white toilet in the rest room. ...</td>\n",
       "      <td>toilet</td>\n",
       "      <td>a urinal in a bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>581781</td>\n",
       "      <td>000000581781.jpg</td>\n",
       "      <td>data/coco/val2017/000000581781.jpg</td>\n",
       "      <td>A store display filled with ripe, unripe banan...</td>\n",
       "      <td>banana</td>\n",
       "      <td>a display of bananas and other fruits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id         file_name                          image_path  \\\n",
       "0          139  000000000139.jpg  data/coco/val2017/000000000139.jpg   \n",
       "1          285  000000000285.jpg  data/coco/val2017/000000000285.jpg   \n",
       "2          632  000000000632.jpg  data/coco/val2017/000000000632.jpg   \n",
       "3          724  000000000724.jpg  data/coco/val2017/000000000724.jpg   \n",
       "4          776  000000000776.jpg  data/coco/val2017/000000000776.jpg   \n",
       "...        ...               ...                                 ...   \n",
       "4995    581317  000000581317.jpg  data/coco/val2017/000000581317.jpg   \n",
       "4996    581357  000000581357.jpg  data/coco/val2017/000000581357.jpg   \n",
       "4997    581482  000000581482.jpg  data/coco/val2017/000000581482.jpg   \n",
       "4998    581615  000000581615.jpg  data/coco/val2017/000000581615.jpg   \n",
       "4999    581781  000000581781.jpg  data/coco/val2017/000000581781.jpg   \n",
       "\n",
       "                                                caption  \\\n",
       "0     A woman stands in the dining area at the table...   \n",
       "1     A big burly grizzly bear is show with grass in...   \n",
       "2     Bedroom scene with a bookcase, blue comforter ...   \n",
       "3     A stop sign is mounted upside-down on it's pos...   \n",
       "4     Three teddy bears, each a different color, snu...   \n",
       "...                                                 ...   \n",
       "4995  A woman holding a small item in a field. Woman...   \n",
       "4996  Skate boarder hang time with young man appeari...   \n",
       "4997  A fancy metal cloth is seen against huge barre...   \n",
       "4998  A picture of a white toilet in the rest room. ...   \n",
       "4999  A store display filled with ripe, unripe banan...   \n",
       "\n",
       "                                                   name  \\\n",
       "0     book,chair,clock,dining table,microwave,person...   \n",
       "1                                                  bear   \n",
       "2                           bed,book,chair,potted plant   \n",
       "3                                   car,stop sign,truck   \n",
       "4                                        bed,teddy bear   \n",
       "...                                                 ...   \n",
       "4995                                  cell phone,person   \n",
       "4996                            bench,person,skateboard   \n",
       "4997                                              clock   \n",
       "4998                                             toilet   \n",
       "4999                                             banana   \n",
       "\n",
       "                                          blip2_caption  \n",
       "0            a living room with a fireplace and a table  \n",
       "1                     a brown bear sitting on the grass  \n",
       "2     a bedroom with a bed, a dresser, a bookcase an...  \n",
       "3                        a stop sign on a street corner  \n",
       "4                          a group of three teddy bears  \n",
       "...                                                 ...  \n",
       "4995                         a woman standing on a hill  \n",
       "4996                              a man on a skateboard  \n",
       "4997  a large clock in a large building with a large...  \n",
       "4998                             a urinal in a bathroom  \n",
       "4999              a display of bananas and other fruits  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blip2_captioned_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xretrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
