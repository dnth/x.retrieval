{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                    Available Datasets                     </span>\n",
       "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Dataset Name  </span>┃<span style=\"font-weight: bold\"> Description                             </span>┃\n",
       "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> coco-val-2017 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> The COCO Validation Set with 5k images. </span>│\n",
       "└───────────────┴─────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                    Available Datasets                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDataset Name \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDescription                            \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mcoco-val-2017\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mThe COCO Validation Set with 5k images.\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────┴─────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xretrieval\n",
    "\n",
    "xretrieval.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Available Models                         </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Model ID                                         </span>┃<span style=\"font-weight: bold\"> Model Input </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers/Salesforce/blip2-itm-vit-g          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text-image  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers/Salesforce/blip2-itm-vit-g-text     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers/Salesforce/blip2-itm-vit-g-image    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> image       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/paraphrase-MiniLM-L3-v2    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/paraphrase-albert-small-v2 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/multi-qa-distilbert-cos-v1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-MiniLM-L12-v2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-distilroberta-v1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/multi-qa-mpnet-base-dot-v1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-mpnet-base-v2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/multi-qa-MiniLM-L6-cos-v1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-MiniLM-L6-v2           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm/resnet18.a1_in1k                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> image       </span>│\n",
       "└──────────────────────────────────────────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Available Models                         \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mModel ID                                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModel Input\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers/Salesforce/blip2-itm-vit-g         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext-image \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers/Salesforce/blip2-itm-vit-g-text    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers/Salesforce/blip2-itm-vit-g-image   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mimage      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/paraphrase-MiniLM-L3-v2   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/paraphrase-albert-small-v2\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/multi-qa-distilbert-cos-v1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-MiniLM-L12-v2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-distilroberta-v1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/multi-qa-mpnet-base-dot-v1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-mpnet-base-v2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/multi-qa-MiniLM-L6-cos-v1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-MiniLM-L6-v2          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm/resnet18.a1_in1k                           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mimage      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────────────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xretrieval.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-21 14:31:24.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxretrieval.datasets.coco\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mCOCO validation dataset found in data/coco/val2017, skipping download\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = xretrieval.load_dataset(\"coco-val-2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>data/coco/val2017/000000000139.jpg</td>\n",
       "      <td>A woman stands in the dining area at the table...</td>\n",
       "      <td>book,chair,clock,dining table,microwave,person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>000000000285.jpg</td>\n",
       "      <td>data/coco/val2017/000000000285.jpg</td>\n",
       "      <td>A big burly grizzly bear is show with grass in...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>000000000632.jpg</td>\n",
       "      <td>data/coco/val2017/000000000632.jpg</td>\n",
       "      <td>Bedroom scene with a bookcase, blue comforter ...</td>\n",
       "      <td>bed,book,chair,potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724</td>\n",
       "      <td>000000000724.jpg</td>\n",
       "      <td>data/coco/val2017/000000000724.jpg</td>\n",
       "      <td>A stop sign is mounted upside-down on it's pos...</td>\n",
       "      <td>car,stop sign,truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>776</td>\n",
       "      <td>000000000776.jpg</td>\n",
       "      <td>data/coco/val2017/000000000776.jpg</td>\n",
       "      <td>Three teddy bears, each a different color, snu...</td>\n",
       "      <td>bed,teddy bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>581317</td>\n",
       "      <td>000000581317.jpg</td>\n",
       "      <td>data/coco/val2017/000000581317.jpg</td>\n",
       "      <td>A woman holding a small item in a field. Woman...</td>\n",
       "      <td>cell phone,person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>581357</td>\n",
       "      <td>000000581357.jpg</td>\n",
       "      <td>data/coco/val2017/000000581357.jpg</td>\n",
       "      <td>Skate boarder hang time with young man appeari...</td>\n",
       "      <td>bench,person,skateboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>581482</td>\n",
       "      <td>000000581482.jpg</td>\n",
       "      <td>data/coco/val2017/000000581482.jpg</td>\n",
       "      <td>A fancy metal cloth is seen against huge barre...</td>\n",
       "      <td>clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>581615</td>\n",
       "      <td>000000581615.jpg</td>\n",
       "      <td>data/coco/val2017/000000581615.jpg</td>\n",
       "      <td>A picture of a white toilet in the rest room. ...</td>\n",
       "      <td>toilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>581781</td>\n",
       "      <td>000000581781.jpg</td>\n",
       "      <td>data/coco/val2017/000000581781.jpg</td>\n",
       "      <td>A store display filled with ripe, unripe banan...</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id         file_name                          image_path  \\\n",
       "0          139  000000000139.jpg  data/coco/val2017/000000000139.jpg   \n",
       "1          285  000000000285.jpg  data/coco/val2017/000000000285.jpg   \n",
       "2          632  000000000632.jpg  data/coco/val2017/000000000632.jpg   \n",
       "3          724  000000000724.jpg  data/coco/val2017/000000000724.jpg   \n",
       "4          776  000000000776.jpg  data/coco/val2017/000000000776.jpg   \n",
       "...        ...               ...                                 ...   \n",
       "4995    581317  000000581317.jpg  data/coco/val2017/000000581317.jpg   \n",
       "4996    581357  000000581357.jpg  data/coco/val2017/000000581357.jpg   \n",
       "4997    581482  000000581482.jpg  data/coco/val2017/000000581482.jpg   \n",
       "4998    581615  000000581615.jpg  data/coco/val2017/000000581615.jpg   \n",
       "4999    581781  000000581781.jpg  data/coco/val2017/000000581781.jpg   \n",
       "\n",
       "                                                caption  \\\n",
       "0     A woman stands in the dining area at the table...   \n",
       "1     A big burly grizzly bear is show with grass in...   \n",
       "2     Bedroom scene with a bookcase, blue comforter ...   \n",
       "3     A stop sign is mounted upside-down on it's pos...   \n",
       "4     Three teddy bears, each a different color, snu...   \n",
       "...                                                 ...   \n",
       "4995  A woman holding a small item in a field. Woman...   \n",
       "4996  Skate boarder hang time with young man appeari...   \n",
       "4997  A fancy metal cloth is seen against huge barre...   \n",
       "4998  A picture of a white toilet in the rest room. ...   \n",
       "4999  A store display filled with ripe, unripe banan...   \n",
       "\n",
       "                                                   name  \n",
       "0     book,chair,clock,dining table,microwave,person...  \n",
       "1                                                  bear  \n",
       "2                           bed,book,chair,potted plant  \n",
       "3                                   car,stop sign,truck  \n",
       "4                                        bed,teddy bear  \n",
       "...                                                 ...  \n",
       "4995                                  cell phone,person  \n",
       "4996                            bench,person,skateboard  \n",
       "4997                                              clock  \n",
       "4998                                             toilet  \n",
       "4999                                             banana  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Available Models                              </span>\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Implementation </span>┃<span style=\"font-weight: bold\"> Model ID                          </span>┃<span style=\"font-weight: bold\"> Input --&gt; Output    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b-coco    </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-flan-t5-xxl      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-2.7b         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> sashakunitsyn/vlrm-blip2-opt-2.7b </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "└────────────────┴───────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                              Available Models                              \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mImplementation\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModel ID                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInput --> Output   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b-coco   \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-flan-t5-xxl     \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-2.7b        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35msashakunitsyn/vlrm-blip2-opt-2.7b\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "└────────────────┴───────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xinfer\n",
    "\n",
    "xinfer.list_models(\"blip2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-21 14:31:26.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mModel: sashakunitsyn/vlrm-blip2-opt-2.7b\u001b[0m\n",
      "\u001b[32m2024-11-21 14:31:26.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mDevice: cuda\u001b[0m\n",
      "\u001b[32m2024-11-21 14:31:26.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mDtype: float16\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75d5c5fb18349619815382125dd5008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/mambaforge-pypy3/envs/xretrieval/lib/python3.11/site-packages/xinfer/transformers/vlrm_blip2.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  finetuned_weights_state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "model = xinfer.create_model(\"sashakunitsyn/vlrm-blip2-opt-2.7b\", device=\"cuda\", dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_id', 'file_name', 'image_path', 'caption', 'name'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_captions_batch(examples):\n",
    "    image_paths = [filename for filename in examples['image_path']]\n",
    "    prompts = [\"\"] * len(image_paths) \n",
    "    \n",
    "    results = model.infer_batch(image_paths, prompts, max_new_tokens=60)\n",
    "    captions = [res.text for res in results]\n",
    "\n",
    "    examples['caption'] = captions\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee814c715994b28adebb2e98906918c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating captions:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_id', 'file_name', 'image_path', 'caption', 'name'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlrm_captioned_dataset = dataset.map(\n",
    "    generate_captions_batch,\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    desc=\"Generating captions\",\n",
    ")\n",
    "vlrm_captioned_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vlrm_captioned_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>data/coco/val2017/000000000139.jpg</td>\n",
       "      <td>a hardwood floor, with a green, pink, yellow, ...</td>\n",
       "      <td>book,chair,clock,dining table,microwave,person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>000000000285.jpg</td>\n",
       "      <td>data/coco/val2017/000000000285.jpg</td>\n",
       "      <td>a brown bear with a mouth open sitting down, w...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>000000000632.jpg</td>\n",
       "      <td>data/coco/val2017/000000000632.jpg</td>\n",
       "      <td>a blue quilt with a blue comforter and a potte...</td>\n",
       "      <td>bed,book,chair,potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724</td>\n",
       "      <td>000000000724.jpg</td>\n",
       "      <td>data/coco/val2017/000000000724.jpg</td>\n",
       "      <td>a red stop sign topped with a shrubbery and a ...</td>\n",
       "      <td>car,stop sign,truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>776</td>\n",
       "      <td>000000000776.jpg</td>\n",
       "      <td>data/coco/val2017/000000000776.jpg</td>\n",
       "      <td>a group of three brown, orange, and light brow...</td>\n",
       "      <td>bed,teddy bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>581317</td>\n",
       "      <td>000000581317.jpg</td>\n",
       "      <td>data/coco/val2017/000000581317.jpg</td>\n",
       "      <td>two pictures of a woman with brown hair in a p...</td>\n",
       "      <td>cell phone,person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>581357</td>\n",
       "      <td>000000581357.jpg</td>\n",
       "      <td>data/coco/val2017/000000581357.jpg</td>\n",
       "      <td>a guy wearing a red sweatshirt jumping a skate...</td>\n",
       "      <td>bench,person,skateboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>581482</td>\n",
       "      <td>000000581482.jpg</td>\n",
       "      <td>data/coco/val2017/000000581482.jpg</td>\n",
       "      <td>a silver clock sitting next to a set of arches...</td>\n",
       "      <td>clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>581615</td>\n",
       "      <td>000000581615.jpg</td>\n",
       "      <td>data/coco/val2017/000000581615.jpg</td>\n",
       "      <td>a pair of white urinals with a qr code on them...</td>\n",
       "      <td>toilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>581781</td>\n",
       "      <td>000000581781.jpg</td>\n",
       "      <td>data/coco/val2017/000000581781.jpg</td>\n",
       "      <td>a bunch of green bananas, a bunch of kiwis, an...</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id         file_name                          image_path  \\\n",
       "0          139  000000000139.jpg  data/coco/val2017/000000000139.jpg   \n",
       "1          285  000000000285.jpg  data/coco/val2017/000000000285.jpg   \n",
       "2          632  000000000632.jpg  data/coco/val2017/000000000632.jpg   \n",
       "3          724  000000000724.jpg  data/coco/val2017/000000000724.jpg   \n",
       "4          776  000000000776.jpg  data/coco/val2017/000000000776.jpg   \n",
       "...        ...               ...                                 ...   \n",
       "4995    581317  000000581317.jpg  data/coco/val2017/000000581317.jpg   \n",
       "4996    581357  000000581357.jpg  data/coco/val2017/000000581357.jpg   \n",
       "4997    581482  000000581482.jpg  data/coco/val2017/000000581482.jpg   \n",
       "4998    581615  000000581615.jpg  data/coco/val2017/000000581615.jpg   \n",
       "4999    581781  000000581781.jpg  data/coco/val2017/000000581781.jpg   \n",
       "\n",
       "                                                caption  \\\n",
       "0     a hardwood floor, with a green, pink, yellow, ...   \n",
       "1     a brown bear with a mouth open sitting down, w...   \n",
       "2     a blue quilt with a blue comforter and a potte...   \n",
       "3     a red stop sign topped with a shrubbery and a ...   \n",
       "4     a group of three brown, orange, and light brow...   \n",
       "...                                                 ...   \n",
       "4995  two pictures of a woman with brown hair in a p...   \n",
       "4996  a guy wearing a red sweatshirt jumping a skate...   \n",
       "4997  a silver clock sitting next to a set of arches...   \n",
       "4998  a pair of white urinals with a qr code on them...   \n",
       "4999  a bunch of green bananas, a bunch of kiwis, an...   \n",
       "\n",
       "                                                   name  \n",
       "0     book,chair,clock,dining table,microwave,person...  \n",
       "1                                                  bear  \n",
       "2                           bed,book,chair,potted plant  \n",
       "3                                   car,stop sign,truck  \n",
       "4                                        bed,teddy bear  \n",
       "...                                                 ...  \n",
       "4995                                  cell phone,person  \n",
       "4996                            bench,person,skateboard  \n",
       "4997                                              clock  \n",
       "4998                                             toilet  \n",
       "4999                                             banana  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"vlrm_captioned_coco_val_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xretrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
