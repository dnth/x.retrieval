{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Available Models                         </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Model ID                                         </span>┃<span style=\"font-weight: bold\"> Model Input </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers/Salesforce/blip2-itm-vit-g-text     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers/Salesforce/blip2-itm-vit-g-image    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> image       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/paraphrase-MiniLM-L3-v2    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/paraphrase-albert-small-v2 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/multi-qa-distilbert-cos-v1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-MiniLM-L12-v2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-distilroberta-v1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/multi-qa-mpnet-base-dot-v1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-mpnet-base-v2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/multi-qa-MiniLM-L6-cos-v1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/all-MiniLM-L6-v2           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> text        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm/resnet18.a1_in1k                            </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> image       </span>│\n",
       "└──────────────────────────────────────────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Available Models                         \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mModel ID                                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModel Input\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers/Salesforce/blip2-itm-vit-g-text    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers/Salesforce/blip2-itm-vit-g-image   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mimage      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/paraphrase-MiniLM-L3-v2   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/paraphrase-albert-small-v2\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/multi-qa-distilbert-cos-v1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-MiniLM-L12-v2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-distilroberta-v1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/multi-qa-mpnet-base-dot-v1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-mpnet-base-v2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/multi-qa-MiniLM-L6-cos-v1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/all-MiniLM-L6-v2          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtext       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm/resnet18.a1_in1k                           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mimage      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────────────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xretrieval\n",
    "\n",
    "xretrieval.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-19 23:21:02.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxretrieval.datasets.coco\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mCOCO validation dataset found in data/coco/val2017, skipping download\u001b[0m\n",
      "\u001b[32m2024-11-19 23:21:06.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxretrieval.core\u001b[0m:\u001b[36mrun_benchmark\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mEncoding text for transformers/Salesforce/blip2-itm-vit-g-text on column `caption`\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c4b14b90f9493aac1659103b3b6be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding captions:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in BLIP-2 should be done in processing. Please follow instruction here (https://gist.github.com/zucchini-nlp/e9f20b054fa322f84ac9311d9ab67042) to update your BLIP-2 model. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1db07445de49b995e281261d0b28d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'MRR': 0.2953,\n",
       " 'NormalizedDCG': 0.3469,\n",
       " 'Precision': 0.2226,\n",
       " 'Recall': 0.4864,\n",
       " 'HitRate': 0.4864,\n",
       " 'MAP': 0.2728}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xretrieval.run_benchmark(\n",
    "    dataset_name=\"coco-val-2017\",\n",
    "    model_id=\"transformers/Salesforce/blip2-itm-vit-g-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-19 23:21:10.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxretrieval.datasets.coco\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mCOCO validation dataset found in data/coco/val2017, skipping download\u001b[0m\n",
      "\u001b[32m2024-11-19 23:21:15.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxretrieval.core\u001b[0m:\u001b[36mrun_benchmark\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mEncoding image for transformers/Salesforce/blip2-itm-vit-g-image on column `image_path`\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90b393d0e58444fbc6803b98499f034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding images:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81014e6a8c6b45e0b0ba1ab60145b4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'MRR': 0.2555,\n",
       " 'NormalizedDCG': 0.3128,\n",
       " 'Precision': 0.1865,\n",
       " 'Recall': 0.4558,\n",
       " 'HitRate': 0.4558,\n",
       " 'MAP': 0.2343}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xretrieval.run_benchmark(\n",
    "    dataset_name=\"coco-val-2017\",\n",
    "    model_id=\"transformers/Salesforce/blip2-itm-vit-g-image\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automatic-retrieval-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
